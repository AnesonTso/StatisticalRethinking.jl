
### m8.1stan

m8.1stan is the first model in the Statistical Rethinking book (pp. 249) using Stan.

Here we will use Turing's NUTS support, which is currently (2018) the originalNUTS by [Hoffman & Gelman]( http://www.stat.columbia.edu/~gelman/research/published/nuts.pdf) and not the one that's in Stan 2.18.2, i.e., Appendix A.5 in: https://arxiv.org/abs/1701.02434

The StatisticalRethinking pkg uses, e.g., Turing, CSV, DataFrames


```julia
using StatisticalRethinking, Turing

Turing.setadbackend(:reverse_diff)
Turing.turnprogress(false) #nb
```

    ┌ Info: Recompiling stale cache file /Users/rob/.julia/compiled/v1.2/StatisticalRethinking/zZGTK.ji for StatisticalRethinking [2d09df54-9d0f-5258-8220-54c2a3d4fbee]
    └ @ Base loading.jl:1184


    loaded


    ┌ Info: [Turing]: global PROGRESS is set as false
    └ @ Turing /Users/rob/.julia/packages/Turing/xp88X/src/Turing.jl:81





    false



Read in rugged data as a DataFrame


```julia
d = CSV.read(rel_path("..", "data",
    "rugged.csv"), delim=';');
# Show size of the DataFrame (should be 234x51)
size(d)
```




    (234, 51)



Apply log() to each element in rgdppc_2000 column and add it as a new column


```julia
d = hcat(d, map(log, d[Symbol("rgdppc_2000")]));
```

Rename our col x1 => log_gdp


```julia
rename!(d, :x1 => :log_gdp);
```

Now we need to drop every row where rgdppc_2000 == missing

When this (https://github.com/JuliaData/DataFrames.jl/pull/1546) hits DataFrame it'll be conceptually easier: i.e., completecases!(d, :rgdppc_2000)


```julia
notisnan(e) = !ismissing(e)
dd = d[map(notisnan, d[:rgdppc_2000]), :];
```

Updated DataFrame dd size (should equal 170 x 52)


```julia
size(dd)
```




    (170, 52)



Define the Turing model


```julia
@model m8_1stan(y, x₁, x₂) = begin
    σ ~ Truncated(Cauchy(0, 2), 0, Inf)
    βR ~ Normal(0, 10)
    βA ~ Normal(0, 10)
    βAR ~ Normal(0, 10)
    α ~ Normal(0, 100)

    for i ∈ 1:length(y)
        y[i] ~ Normal(α + βR * x₁[i] + βA * x₂[i] + βAR * x₁[i] * x₂[i], σ)
    end
end;
```

Test to see that the model is sane. Use 2000 for now, as in the book.
Need to set the same stepsize and adapt_delta as in Stan...

Use Turing mcmc


```julia
posterior = sample(m8_1stan(dd[:log_gdp], dd[:rugged], dd[:cont_africa]),
    Turing.NUTS(2000, 200, 0.95));
# Describe the posterior samples
describe(posterior)
```

    ┌ Info: [Turing] looking for good initial eps...
    └ @ Turing /Users/rob/.julia/packages/Turing/xp88X/src/samplers/support/hmc_core.jl:246
    [NUTS{Turing.FluxTrackerAD,Union{}}] found initial ϵ: 0.05
    └ @ Turing /Users/rob/.julia/packages/Turing/xp88X/src/samplers/support/hmc_core.jl:291
    ┌ Info:  Adapted ϵ = 0.027030945408177368, std = [1.0, 1.0, 1.0, 1.0, 1.0]; 200 iterations is used for adaption.
    └ @ Turing /Users/rob/.julia/packages/Turing/xp88X/src/samplers/adapt/adapt.jl:91


    [NUTS] Finished with
      Running time        = 246.10006934400036;
      #lf / sample        = 0.0015;
      #evals / sample     = 45.228;
      pre-cond. metric    = [1.0, 1.0, 1.0, 1.0, 1.0].
    Iterations = 1:2000
    Thinning interval = 1
    Chains = 1
    Samples per chain = 2000
    
    Empirical Posterior Estimates:
                  Mean           SD         Naive SE        MCSE         ESS   
           α    9.188088348  0.396871357 0.00887431332 0.02039580300  378.63251
      lf_num    0.001500000  0.067082039 0.00150000000 0.00150000000 2000.00000
          βA   -1.911748293  0.332845971 0.00744266218 0.01678874483  393.05213
          βR   -0.192567599  0.126597842 0.00283081381 0.00556124014  518.21420
           σ    0.979277273  0.574983336 0.01285701826 0.02762306628  433.27811
     elapsed    0.123050035  0.112029348 0.00250505239 0.00365561704  939.16572
     epsilon    0.027775987  0.014520776 0.00032469443 0.00052470264  765.86669
    eval_num   45.228000000 25.405328799 0.56808042184 0.61015166363 1733.70036
         βAR    0.385937411  0.141733785 0.00316926379 0.00542323507  683.01448
          lp -249.895980131 18.875323625 0.42206506722 1.26349762411  223.17213
      lf_eps    0.027775987  0.014520776 0.00032469443 0.00052470264  765.86669
    
    Quantiles:
                  2.5%           25.0%          50.0%          75.0%          97.5%    
           α    8.914525568    9.103290446    9.207484253    9.314196045    9.497320009
      lf_num    0.000000000    0.000000000    0.000000000    0.000000000    0.000000000
          βA   -2.387287116   -2.091614997   -1.914481358   -1.755178739   -1.471547382
          βR   -0.354413189   -0.255736860   -0.194691494   -0.140923106   -0.038435717
           σ    0.854148063    0.914868754    0.949824692    0.987314681    1.067955927
     elapsed    0.022774916    0.058130668    0.118208148    0.134882829    0.262489473
     epsilon    0.022700360    0.027030945    0.027030945    0.027030945    0.035644644
    eval_num   10.000000000   22.000000000   46.000000000   46.000000000   94.000000000
         βAR    0.108093386    0.298329907    0.381139774    0.475528425    0.658978123
          lp -252.894911383 -249.602424413 -248.326264205 -247.445537812 -246.444371185
      lf_eps    0.022700360    0.027030945    0.027030945    0.027030945    0.035644644
    


Example of a Turing run simulation output


```julia
m81turing = "
             Mean                SD             Naive SE           MCSE             ESS
α    9.2140454953  0.416410339 0.00931121825 0.0303436655  188.324543
βA  -1.9414588557  0.373885658 0.00836033746 0.0583949856   40.994586
βR  -0.1987645549  0.158902372 0.00355316505 0.0128657961  152.541295
σ    0.9722532977  0.440031013 0.00983939257 0.0203736871  466.473854
βAR  0.3951414223  0.187780491 0.00419889943 0.0276680621   46.062071
";
```

Here's the map2stan output from rethinking, note above that SD is too large


```julia
m81map2stan = "
       Mean StdDev lower 0.89 upper 0.89 n_eff Rhat
 a      9.24   0.14       9.03       9.47   291    1
 bR    -0.21   0.08      -0.32      -0.07   306    1
 bA    -1.97   0.23      -2.31      -1.58   351    1
 bAR    0.40   0.13       0.20       0.63   350    1
 sigma  0.95   0.05       0.86       1.03   566    1
";#-
```

*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*
