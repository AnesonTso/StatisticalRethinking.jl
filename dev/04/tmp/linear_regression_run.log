method = sample (Default)
method = sample (Default)
  sample
  sample
    num_samples = 1000 (Default)
    num_samples = 1000 (Default)
    num_warmup = 1000 (Default)
    num_warmup = 1000 (Default)
    save_warmup = 0 (Default)
    save_warmup = 0 (Default)
    thin = 1 (Default)
    thin = 1 (Default)
    adapt
    adapt
      engaged = 1 (Default)
      engaged = 1 (Default)
      gamma = 0.050000000000000003 (Default)
      gamma = 0.050000000000000003 (Default)
      delta = 0.80000000000000004 (Default)
      delta = 0.80000000000000004 (Default)
      kappa = 0.75 (Default)
      kappa = 0.75 (Default)
      t0 = 10 (Default)
      t0 = 10 (Default)
      init_buffer = 75 (Default)
      term_buffer = 50 (Default)
      window = 25 (Default)
    algorithm = hmc (Default)
      init_buffer = 75 (Default)
      hmc
      term_buffer = 50 (Default)
        engine = nuts (Default)
      window = 25 (Default)
          nuts
    algorithm = hmc (Default)
            max_depth = 10 (Default)
      hmc
        metric = diag_e (Default)
        engine = nuts (Default)
        metric_file =  (Default)
          nuts
        stepsize = 1 (Default)
            max_depth = 10 (Default)
        stepsize_jitter = 1
        metric = diag_e (Default)
id = 1
        metric_file =  (Default)
data
        stepsize = 1 (Default)
  file = linear_regression_1.data.R
        stepsize_jitter = 1
init = 2 (Default)
id = 2
random
data
  seed = 81778047
  file = linear_regression_2.data.R
output
init = 2 (Default)
  file = linear_regression_samples_1.csv
random
  diagnostic_file =  (Default)
  seed = 81778047
  refresh = 100 (Default)
output

  file = linear_regression_samples_2.csv
  diagnostic_file =  (Default)
  refresh = 100 (Default)

method = sample (Default)
  sample
method = sample (Default)
    num_samples = 1000 (Default)
  sample
    num_warmup = 1000 (Default)
    num_samples = 1000 (Default)
    save_warmup = 0 (Default)
    thin = 1 (Default)
    num_warmup = 1000 (Default)
    adapt
      engaged = 1 (Default)
    save_warmup = 0 (Default)
    thin = 1 (Default)
      gamma = 0.050000000000000003 (Default)
    adapt
      engaged = 1 (Default)
      delta = 0.80000000000000004 (Default)
      kappa = 0.75 (Default)
      gamma = 0.050000000000000003 (Default)
      t0 = 10 (Default)
      init_buffer = 75 (Default)
      term_buffer = 50 (Default)
      delta = 0.80000000000000004 (Default)
      window = 25 (Default)
      kappa = 0.75 (Default)
    algorithm = hmc (Default)
      hmc
      t0 = 10 (Default)
        engine = nuts (Default)
      init_buffer = 75 (Default)
          nuts
      term_buffer = 50 (Default)
            max_depth = 10 (Default)
      window = 25 (Default)
        metric = diag_e (Default)
    algorithm = hmc (Default)
        metric_file =  (Default)
      hmc
        stepsize = 1 (Default)
        engine = nuts (Default)
        stepsize_jitter = 1
          nuts
id = 4
            max_depth = 10 (Default)
data
        metric = diag_e (Default)
  file = linear_regression_4.data.R
        metric_file =  (Default)
init = 2 (Default)
random
        stepsize = 1 (Default)
  seed = 81778051
output
  file = linear_regression_samples_4.csv
        stepsize_jitter = 1
  diagnostic_file =  (Default)
id = 3
  refresh = 100 (Default)
data

  file = linear_regression_3.data.R
init = 2 (Default)
random
  seed = 81778051
output
  file = linear_regression_samples_3.csv
  diagnostic_file =  (Default)
  refresh = 100 (Default)

Rejecting initial value:
Rejecting initial value:
  Error evaluating the log probability at the initial value.
  Error evaluating the log probability at the initial value.
Exception: normal_lpdf: Scale parameter is -1.27205, but must be > 0!  (in '/home/travis/build/StatisticalRethinkingJulia/StatisticalRethinking.jl/docs/build/04/tmp/linear_regression.stan' at line 21)

Exception: normal_lpdf: Scale parameter is -1.01347, but must be > 0!  (in '/home/travis/build/StatisticalRethinkingJulia/StatisticalRethinking.jl/docs/build/04/tmp/linear_regression.stan' at line 21)

Rejecting initial value:

  Error evaluating the log probability at the initial value.
Exception: normal_lpdf: Scale parameter is -0.600307, but must be > 0!  (in '/home/travis/build/StatisticalRethinkingJulia/StatisticalRethinking.jl/docs/build/04/tmp/linear_regression.stan' at line 21)

Gradient evaluation took 6e-05 seconds
1000 transitions using 10 leapfrog steps per transition would take 0.6 seconds.
Adjust your expectations accordingly!


Rejecting initial value:
  Error evaluating the log probability at the initial value.
Exception: normal_lpdf: Scale parameter is -1.91758, but must be > 0!  (in '/home/travis/build/StatisticalRethinkingJulia/StatisticalRethinking.jl/docs/build/04/tmp/linear_regression.stan' at line 21)


Gradient evaluation took 8e-05 seconds
1000 transitions using 10 leapfrog steps per transition would take 0.8 seconds.
Adjust your expectations accordingly!


Iteration:    1 / 2000 [  0%]  (Warmup)
Iteration:    1 / 2000 [  0%]  (Warmup)

Gradient evaluation took 4.7e-05 seconds
1000 transitions using 10 leapfrog steps per transition would take 0.47 seconds.
Adjust your expectations accordingly!


Iteration:    1 / 2000 [  0%]  (Warmup)
Rejecting initial value:
  Error evaluating the log probability at the initial value.
Exception: normal_lpdf: Scale parameter is -1.08961, but must be > 0!  (in '/home/travis/build/StatisticalRethinkingJulia/StatisticalRethinking.jl/docs/build/04/tmp/linear_regression.stan' at line 21)

Rejecting initial value:
  Error evaluating the log probability at the initial value.
Exception: normal_lpdf: Scale parameter is -1.72331, but must be > 0!  (in '/home/travis/build/StatisticalRethinkingJulia/StatisticalRethinking.jl/docs/build/04/tmp/linear_regression.stan' at line 21)


Gradient evaluation took 5.2e-05 seconds
1000 transitions using 10 leapfrog steps per transition would take 0.52 seconds.
Adjust your expectations accordingly!


Iteration:    1 / 2000 [  0%]  (Warmup)
Iteration:  100 / 2000 [  5%]  (Warmup)
Iteration:  100 / 2000 [  5%]  (Warmup)
Iteration:  100 / 2000 [  5%]  (Warmup)
Iteration:  200 / 2000 [ 10%]  (Warmup)
Iteration:  200 / 2000 [ 10%]  (Warmup)
Iteration:  100 / 2000 [  5%]  (Warmup)
Iteration:  200 / 2000 [ 10%]  (Warmup)
Iteration:  300 / 2000 [ 15%]  (Warmup)
Iteration:  300 / 2000 [ 15%]  (Warmup)
Iteration:  200 / 2000 [ 10%]  (Warmup)
Iteration:  300 / 2000 [ 15%]  (Warmup)
Iteration:  400 / 2000 [ 20%]  (Warmup)
Iteration:  400 / 2000 [ 20%]  (Warmup)
Iteration:  300 / 2000 [ 15%]  (Warmup)
Iteration:  400 / 2000 [ 20%]  (Warmup)
Iteration:  500 / 2000 [ 25%]  (Warmup)
Iteration:  500 / 2000 [ 25%]  (Warmup)
Iteration:  400 / 2000 [ 20%]  (Warmup)
Iteration:  500 / 2000 [ 25%]  (Warmup)
Iteration:  500 / 2000 [ 25%]  (Warmup)
Iteration:  600 / 2000 [ 30%]  (Warmup)
Iteration:  600 / 2000 [ 30%]  (Warmup)
Iteration:  700 / 2000 [ 35%]  (Warmup)
Iteration:  600 / 2000 [ 30%]  (Warmup)
Iteration:  600 / 2000 [ 30%]  (Warmup)
Iteration:  700 / 2000 [ 35%]  (Warmup)
Iteration:  800 / 2000 [ 40%]  (Warmup)
Iteration:  700 / 2000 [ 35%]  (Warmup)
Iteration:  800 / 2000 [ 40%]  (Warmup)
Iteration:  700 / 2000 [ 35%]  (Warmup)
Iteration:  800 / 2000 [ 40%]  (Warmup)
Iteration:  900 / 2000 [ 45%]  (Warmup)
Iteration:  900 / 2000 [ 45%]  (Warmup)
Iteration:  900 / 2000 [ 45%]  (Warmup)
Iteration:  800 / 2000 [ 40%]  (Warmup)
Iteration:  900 / 2000 [ 45%]  (Warmup)
Iteration: 1000 / 2000 [ 50%]  (Warmup)
Iteration: 1001 / 2000 [ 50%]  (Sampling)
Iteration: 1000 / 2000 [ 50%]  (Warmup)
Iteration: 1001 / 2000 [ 50%]  (Sampling)
Iteration: 1000 / 2000 [ 50%]  (Warmup)
Iteration: 1001 / 2000 [ 50%]  (Sampling)
Iteration: 1000 / 2000 [ 50%]  (Warmup)
Iteration: 1001 / 2000 [ 50%]  (Sampling)
Iteration: 1100 / 2000 [ 55%]  (Sampling)
Iteration: 1100 / 2000 [ 55%]  (Sampling)
Iteration: 1100 / 2000 [ 55%]  (Sampling)
Iteration: 1100 / 2000 [ 55%]  (Sampling)
Iteration: 1200 / 2000 [ 60%]  (Sampling)
Iteration: 1200 / 2000 [ 60%]  (Sampling)
Iteration: 1200 / 2000 [ 60%]  (Sampling)
Iteration: 1200 / 2000 [ 60%]  (Sampling)
Iteration: 1300 / 2000 [ 65%]  (Sampling)
Iteration: 1300 / 2000 [ 65%]  (Sampling)
Iteration: 1300 / 2000 [ 65%]  (Sampling)
Iteration: 1300 / 2000 [ 65%]  (Sampling)
Iteration: 1400 / 2000 [ 70%]  (Sampling)
Iteration: 1400 / 2000 [ 70%]  (Sampling)
Iteration: 1400 / 2000 [ 70%]  (Sampling)
Iteration: 1400 / 2000 [ 70%]  (Sampling)
Iteration: 1500 / 2000 [ 75%]  (Sampling)
Iteration: 1500 / 2000 [ 75%]  (Sampling)
Iteration: 1500 / 2000 [ 75%]  (Sampling)
Iteration: 1500 / 2000 [ 75%]  (Sampling)
Iteration: 1600 / 2000 [ 80%]  (Sampling)
Iteration: 1600 / 2000 [ 80%]  (Sampling)
Iteration: 1600 / 2000 [ 80%]  (Sampling)
Iteration: 1600 / 2000 [ 80%]  (Sampling)
Iteration: 1700 / 2000 [ 85%]  (Sampling)
Iteration: 1700 / 2000 [ 85%]  (Sampling)
Iteration: 1700 / 2000 [ 85%]  (Sampling)
Iteration: 1700 / 2000 [ 85%]  (Sampling)
Iteration: 1800 / 2000 [ 90%]  (Sampling)
Iteration: 1800 / 2000 [ 90%]  (Sampling)
Iteration: 1800 / 2000 [ 90%]  (Sampling)
Iteration: 1900 / 2000 [ 95%]  (Sampling)
Iteration: 1800 / 2000 [ 90%]  (Sampling)
Iteration: 1900 / 2000 [ 95%]  (Sampling)
Iteration: 1900 / 2000 [ 95%]  (Sampling)
Iteration: 2000 / 2000 [100%]  (Sampling)

 Elapsed Time: 0.074202 seconds (Warm-up)
               0.177233 seconds (Sampling)
               0.251435 seconds (Total)

Iteration: 2000 / 2000 [100%]  (Sampling)

 Elapsed Time: 0.078087 seconds (Warm-up)
               0.170684 seconds (Sampling)
               0.248771 seconds (Total)

Iteration: 1900 / 2000 [ 95%]  (Sampling)
Iteration: 2000 / 2000 [100%]  (Sampling)

 Elapsed Time: 0.07052 seconds (Warm-up)
               0.198281 seconds (Sampling)
               0.268801 seconds (Total)

Iteration: 2000 / 2000 [100%]  (Sampling)

 Elapsed Time: 0.07024 seconds (Warm-up)
               0.196888 seconds (Sampling)
               0.267128 seconds (Total)

