{
 "cells": [
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "# Estimate Bernoulli draws probabilility"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "We estimate a simple model of ``n`` independent Bernoulli draws, with\n",
    "probability ``α``. First, we load the packages we use."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using StatisticalRethinking\n",
    "using TransformVariables\n",
    "using LogDensityProblems\n",
    "using DynamicHMC\n",
    "using MCMCDiagnostics\n",
    "using Parameters\n",
    "using Statistics"
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Then define a structure to hold the data.\n",
    "For this model, the number of draws equal to `1` is a sufficient statistic."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Main.##374.BernoulliProblem"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Toy problem using a Bernoulli distribution.\n",
    "We model `n` independent draws from a ``Bernoulli(α)`` distribution.\n",
    "\"\"\"\n",
    "struct BernoulliProblem\n",
    "    \"Total number of draws in the data.\"\n",
    "    n::Int\n",
    "    \"Number of draws `==1` in the data\"\n",
    "    s::Vector{Int}\n",
    "end"
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Then make the type callable with the parameters *as a single argument*.  We\n",
    "use decomposition in the arguments, but it could be done inside the function,\n",
    "too."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function (problem::BernoulliProblem)((α, )::NamedTuple{(:α, )})\n",
    "    @unpack n, s = problem        # extract the data\n",
    "    # log likelihood: the constant log(combinations(n, s)) term\n",
    "    # has been dropped since it is irrelevant to sampling.\n",
    "    #sum([s1 * log(α) + (n-s1) * log(1-α) for s1 in s])\n",
    "    loglikelihood(Binomial(n, α), s)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": 3
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "We should test this, also, this would be a good place to benchmark and\n",
    "optimize more complicated problems."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "-2.6548056865833978"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "cell_type": "code",
   "source": [
    "obs = rand(Binomial(9, 2/3), 1)\n",
    "p = BernoulliProblem(9, obs)\n",
    "p((α = 0.5, ))"
   ],
   "metadata": {},
   "execution_count": 4
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Recall that we need to\n",
    "\n",
    "1. transform from ``ℝ`` to the valid parameter domain `(0,1)` for more efficient sampling, and\n",
    "\n",
    "2. calculate the derivatives for this transformed mapping.\n",
    "\n",
    "The helper packages `TransformVariables` and `LogDensityProblems` take care of\n",
    "this. We use a flat prior (the default, omitted)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "P = TransformedLogDensity(as((α = as𝕀,)), p)\n",
    "∇P = ADgradient(:ForwardDiff, P);"
   ],
   "metadata": {},
   "execution_count": 5
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Finally, we sample from the posterior. `chain` holds the chain (positions and\n",
    "diagnostic information), while the second returned value is the tuned sampler\n",
    "which would allow continuation of sampling."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCMC, adapting ϵ (75 steps)\n",
      "0.0015 s/step ...done\n",
      "MCMC, adapting ϵ (25 steps)\n",
      "7.4e-6 s/step ...done\n",
      "MCMC, adapting ϵ (50 steps)\n",
      "0.0026 s/step ...done\n",
      "MCMC, adapting ϵ (100 steps)\n",
      "7.9e-6 s/step ...done\n",
      "MCMC, adapting ϵ (200 steps)\n",
      "7.8e-5 s/step ...done\n",
      "MCMC, adapting ϵ (400 steps)\n",
      "7.1e-6 s/step ...done\n",
      "MCMC, adapting ϵ (50 steps)\n",
      "8.2e-6 s/step ...done\n",
      "MCMC (1000 steps)\n",
      "5.8e-6 s/step ...done\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(DynamicHMC.NUTS_Transition{Array{Float64,1},Float64}[NUTS_Transition{Array{Float64,1},Float64}([1.00779], -3.04514, 2, DoubledTurn, 0.975685, 3), NUTS_Transition{Array{Float64,1},Float64}([0.44519], -3.24392, 1, AdjacentTurn, 0.915135, 3), NUTS_Transition{Array{Float64,1},Float64}([0.141423], -3.77662, 1, DoubledTurn, 0.832607, 1), NUTS_Transition{Array{Float64,1},Float64}([0.141423], -5.09866, 1, AdjacentTurn, 0.646524, 3), NUTS_Transition{Array{Float64,1},Float64}([0.833871], -3.4606, 1, AdjacentTurn, 1.0, 3), NUTS_Transition{Array{Float64,1},Float64}([0.773915], -2.91409, 1, DoubledTurn, 0.992555, 1), NUTS_Transition{Array{Float64,1},Float64}([0.410581], -3.24484, 1, DoubledTurn, 0.896161, 1), NUTS_Transition{Array{Float64,1},Float64}([0.402524], -3.38168, 2, DoubledTurn, 0.998691, 3), NUTS_Transition{Array{Float64,1},Float64}([1.22176], -3.22842, 2, DoubledTurn, 1.0, 3), NUTS_Transition{Array{Float64,1},Float64}([1.22176], -4.66233, 1, AdjacentTurn, 0.628483, 3)  …  NUTS_Transition{Array{Float64,1},Float64}([2.26545], -5.80696, 1, AdjacentTurn, 0.498309, 3), NUTS_Transition{Array{Float64,1},Float64}([2.0164], -4.30477, 1, DoubledTurn, 1.0, 1), NUTS_Transition{Array{Float64,1},Float64}([0.962921], -3.88951, 1, AdjacentTurn, 0.957331, 3), NUTS_Transition{Array{Float64,1},Float64}([0.261229], -3.53103, 1, AdjacentTurn, 0.851356, 3), NUTS_Transition{Array{Float64,1},Float64}([0.690014], -3.30639, 1, DoubledTurn, 1.0, 1), NUTS_Transition{Array{Float64,1},Float64}([0.839829], -2.93572, 1, DoubledTurn, 1.0, 1), NUTS_Transition{Array{Float64,1},Float64}([1.6324], -3.48999, 1, AdjacentTurn, 0.880955, 3), NUTS_Transition{Array{Float64,1},Float64}([0.740066], -3.18445, 2, DoubledTurn, 1.0, 3), NUTS_Transition{Array{Float64,1},Float64}([0.551671], -3.0815, 2, DoubledTurn, 0.982595, 3), NUTS_Transition{Array{Float64,1},Float64}([1.643], -3.9797, 2, DoubledTurn, 0.811249, 3)], NUTS sampler in 1 dimensions\n  stepsize (ϵ) ≈ 1.04\n  maximum depth = 10\n  Gaussian kinetic energy, √diag(M⁻¹): [0.699275]\n)"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "cell_type": "code",
   "source": [
    "chain, NUTS_tuned = NUTS_init_tune_mcmc(∇P, 1000)"
   ],
   "metadata": {},
   "execution_count": 6
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "To get the posterior for ``α``, we need to use `get_position` and\n",
    "then transform"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "posterior = TransformVariables.transform.(Ref(∇P.transformation), get_position.(chain));"
   ],
   "metadata": {},
   "execution_count": 7
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Extract the parameter."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "posterior_α = first.(posterior);"
   ],
   "metadata": {},
   "execution_count": 8
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "check the effective sample size"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "296.51912251589096"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "cell_type": "code",
   "source": [
    "ess_α = effective_sample_size(posterior_α)"
   ],
   "metadata": {},
   "execution_count": 9
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "NUTS-specific statistics"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Hamiltonian Monte Carlo sample of length 1000\n  acceptance rate mean: 0.91, min/25%/median/75%/max: 0.12 0.89 0.97 1.0 1.0\n  termination: AdjacentTurn => 30% DoubledTurn => 70%\n  depth: 1 => 64% 2 => 36%\n"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "cell_type": "code",
   "source": [
    "NUTS_statistics(chain)"
   ],
   "metadata": {},
   "execution_count": 10
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "check the mean"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7247017597415696"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "cell_type": "code",
   "source": [
    "mean(posterior_α)"
   ],
   "metadata": {},
   "execution_count": 11
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0-DEV.219"
  },
  "kernelspec": {
   "name": "julia-1.2",
   "display_name": "Julia 1.2.0-DEV.219",
   "language": "julia"
  }
 },
 "nbformat": 4
}
